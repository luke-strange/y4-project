{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pkg_resources\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import truebayes.network\n",
    "import truebayes.geometry\n",
    "import truebayes.roman\n",
    "import truebayes.loss\n",
    "import truebayes.like\n",
    "import truebayes.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade git+https://github.com/vallis/TrueBayes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "##geometry.py\n",
    "def setgeometry(q):\n",
    "    global qdim, xmin, xmax, xstops, xmid, xwid\n",
    "\n",
    "    # bins\n",
    "    qdim = q\n",
    "\n",
    "    # prior range for x (will be uniform)\n",
    "    xmin, xmax = 0, 1\n",
    "\n",
    "    # definition of quantization bins\n",
    "    xstops = np.linspace(xmin, xmax, qdim + 1)\n",
    "\n",
    "    # to plot histograms\n",
    "    xmid = 0.5 * (xstops[:-1] + xstops[1:])\n",
    "    xwid = xstops[1] - xstops[0]\n",
    "\n",
    "setgeometry(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.py\n",
    "import torch\n",
    "\n",
    "def numpy2cuda(array, single=True):\n",
    "  array = torch.from_numpy(array)\n",
    "  \n",
    "  if single:\n",
    "    array = array.float()\n",
    "    \n",
    "  if torch.cuda.is_available():\n",
    "    array = array.cuda()\n",
    "    \n",
    "  return array\n",
    "\n",
    "\n",
    "def cuda2numpy(tensor):\n",
    "  return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##network.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "\n",
    "def makenet(dims, softmax=True, single=True):\n",
    "  \"\"\"Make a fully connected DNN with layer widths described by `dims`.\n",
    "  CUDA is always enabled, and double precision is set with `single=False`.\n",
    "  The output layer applies a softmax transformation,\n",
    "  disabled by setting `softmax=False`.\"\"\"\n",
    "\n",
    "  ndims = len(dims)\n",
    "\n",
    "  class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      # the weights must be set explicitly as attributes in the class\n",
    "      # (i.e., we can't collect them in a single list)\n",
    "      for l in range(ndims - 1):\n",
    "        layer = nn.Linear(dims[l], dims[l+1])\n",
    "        \n",
    "        if not single:\n",
    "          layer = layer.double()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "          layer = layer.cuda()\n",
    "        \n",
    "        setattr(self, f'fc{l}', layer)\n",
    "                \n",
    "    def forward(self, x):\n",
    "      # per Alvin's recipe, apply relu everywhere but last layer\n",
    "      for l in range(ndims - 2):\n",
    "        x = F.leaky_relu(getattr(self, f'fc{l}')(x), negative_slope=0.2)\n",
    "\n",
    "      x = getattr(self, f'fc{ndims - 2}')(x)\n",
    "\n",
    "      if softmax:\n",
    "        return F.softmax(x, dim=1)\n",
    "      else:\n",
    "        return x\n",
    "  \n",
    "  return Net\n",
    "\n",
    "\n",
    "def makenetbn(dims, softmax=True, single=True):\n",
    "  \"\"\"A batch-normalizing version of makenet. Experimental.\"\"\"\n",
    "\n",
    "  ndims = len(dims)\n",
    "\n",
    "  class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      # the weights must be set explicitly as attributes in the class\n",
    "      # (i.e., we can't collect them in a single list)\n",
    "      for l in range(ndims - 1):\n",
    "        layer = nn.Linear(dims[l], dims[l+1])\n",
    "        bn = nn.BatchNorm1d(num_features=dims[l+1])\n",
    "        \n",
    "        if not single:\n",
    "          layer = layer.double()\n",
    "          bn = bn.double()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "          layer = layer.cuda()\n",
    "          bn = bn.cuda()\n",
    "        \n",
    "        setattr(self, f'fc{l}', layer)\n",
    "        setattr(self, f'bn{l}', bn)\n",
    "                \n",
    "    def forward(self, x):\n",
    "      # per Alvin's recipe, apply relu everywhere but last layer\n",
    "      for l in range(ndims - 2):\n",
    "        x = getattr(self, f'bn{l}')(F.leaky_relu(getattr(self, f'fc{l}')(x), negative_slope=0.2))\n",
    "\n",
    "      x = getattr(self, f'fc{ndims - 2}')(x)\n",
    "\n",
    "      if softmax:\n",
    "        return F.softmax(x, dim=1)\n",
    "      else:\n",
    "        return x\n",
    "  \n",
    "  return Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loss.py\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from truebayes.geometry import qdim\n",
    "from truebayes.utils import numpy2cuda, cuda2numpy\n",
    "\n",
    "def lossfunction(o, l: 'indicator'):\n",
    "  \"\"\"MSE loss for DNN histogram output, labels represented as indicator arrays.\"\"\"\n",
    "\n",
    "  return torch.mean(torch.sum(o**2,dim=1) - 2*torch.sum(o*l,dim=1))\n",
    "\n",
    "\n",
    "def kllossfunction(o, l: 'indicator'):\n",
    "  \"\"\"KL loss for DNN histogram output, labels represented as indicator arrays.\"\"\"\n",
    "\n",
    "  return -torch.mean(2*torch.sum(torch.log(o)*l, dim=1))\n",
    "\n",
    "\n",
    "def lossG1(o, l: 'xtrue'):\n",
    "  \"\"\"MSE loss for normal-PDF output (represented as a mean/variance pair).\"\"\"\n",
    "\n",
    "  # since int N^2(x;x0,s) dx = 1/(2 sqrt(pi) s)\n",
    "  # the sqerr loss is 1/(2 sqrt(pi) s) - 2 * e^{-(x_tr - x0)^2/2 s^2} / sqrt(2 pi s^2)\n",
    "  # multiplying by 2 sqrt(pi)\n",
    "  \n",
    "  return torch.mean((1 - 2*math.sqrt(2)*torch.exp(-0.5*(l - o[:,0])**2/o[:,1]**2)) / o[:,1])\n",
    "\n",
    "\n",
    "def kllossGn(o, l: 'xtrue'):\n",
    "  \"\"\"KL loss for Gaussian-mixture output (represented as a vector of concatenated mean/variance/weight triples).\"\"\"\n",
    "\n",
    "  x0 = o[:,0::3]\n",
    "  std = o[:,1::3]\n",
    "  weight = torch.softmax(o[:,2::3], dim=1)\n",
    "\n",
    "  # numerically unstable\n",
    "  # return -torch.mean(2*torch.log(torch.sum(weight * torch.exp(-0.5*(x0 - l[:,np.newaxis])**2/std**2) / torch.sqrt(2 * math.pi * std**2),dim=1)))\n",
    "  \n",
    "  return -torch.mean(torch.logsumexp(torch.log(weight) - 0.5*(x0 - l[:,np.newaxis])**2/std**2 - 0.5*torch.log(2 * math.pi * std**2), dim=1))\n",
    "\n",
    "\n",
    "def netmeanGn(inputs, net=None, single=True):\n",
    "  if isinstance(inputs, np.ndarray):\n",
    "    inputs = numpy2cuda(inputs, single)\n",
    "    \n",
    "  pars = cuda2numpy(net(inputs))\n",
    "\n",
    "  dx  = pars[:,0::3] \n",
    "  std = pars[:,1::3]\n",
    "  pweight = torch.softmax(torch.from_numpy(pars[:,2::3]),dim=1).numpy()\n",
    "\n",
    "  # see https://en.wikipedia.org/wiki/Mixture_distribution\n",
    "  xmean = np.sum(pweight * dx, axis=1)\n",
    "  xerr  = np.sqrt(np.sum(pweight * (dx**2 + std**2), axis=1) - xmean**2)\n",
    "\n",
    "  return xmean, xerr\n",
    "\n",
    "\n",
    "def kllossfunction2(o, l: 'indicator'):\n",
    "  \"\"\"KL loss over 2-D histogram.\"\"\"\n",
    "\n",
    "  q = o.reshape((o.shape[0], qdim, qdim))\n",
    "\n",
    "  return torch.mean(-torch.sum(torch.log(q)*l, dim=[1,2]))\n",
    "\n",
    "\n",
    "def kllossGn2(o, l: 'xtrue'):\n",
    "  \"\"\"KL loss for Gaussian-mixture output, 2D, precision-matrix parameters.\"\"\"\n",
    "\n",
    "  dx  = o[:,0::6] - l[:,0,np.newaxis]\n",
    "  dy  = o[:,2::6] - l[:,1,np.newaxis]\n",
    "  \n",
    "  # precision matrix is positive definite, so has positive diagonal terms\n",
    "  Fxx = o[:,1::6]**2\n",
    "  Fyy = o[:,3::6]**2\n",
    "  \n",
    "  # precision matrix is positive definite, so has positive \n",
    "  Fxy = torch.atan(o[:,4::6]) / (0.5*math.pi) * o[:,1::6] * o[:,3::6]\n",
    "  \n",
    "  weight = torch.softmax(o[:,5::6], dim=1)\n",
    "   \n",
    "  # omitting the sqrt(4*math*pi) since it's common to all templates\n",
    "  return -torch.mean(torch.logsumexp(torch.log(weight) - 0.5*(Fxx*dx*dx + Fyy*dy*dy + 2*Fxy*dx*dy) + 0.5*torch.log(Fxx*Fyy - Fxy*Fxy), dim=1))\n",
    "\n",
    "\n",
    "def netmeanGn2(inputs, net=None, single=True):\n",
    "  if isinstance(inputs, np.ndarray):\n",
    "    inputs = numpy2cuda(inputs, single)\n",
    "    \n",
    "  pars = cuda2numpy(net(inputs))\n",
    "\n",
    "  dx, dy = pars[:,0::6], pars[:,2::6] \n",
    "  \n",
    "  Fxx, Fyy = pars[:,1::6]**2, pars[:,3::6]**2\n",
    "  Fxy = np.arctan(pars[:,4::6]) / (0.5*math.pi) * pars[:,1::6] * pars[:,3::6]\n",
    "\n",
    "  det = Fxx*Fyy - Fxy*Fxy\n",
    "  Cxx, Cyy, Cxy = Fyy/det, Fxx/det, -Fxy/det\n",
    "\n",
    "  pweight = torch.softmax(torch.from_numpy(pars[:,5::6]),dim=1).numpy()\n",
    "\n",
    "  xmean, ymean = np.sum(pweight * dx, axis=1), np.sum(pweight * dy, axis=1)\n",
    "  xerr,  yerr  = np.sqrt(np.sum(pweight * (dx**2 + Cxx), axis=1) - xmean**2), np.sqrt(np.sum(pweight * (dy**2 + Cyy), axis=1) - ymean**2) \n",
    "  xycov        = np.sum(pweight * (dx*dy + Cxy), axis=1) - xmean*ymean\n",
    "\n",
    "  return np.vstack((xmean, ymean)).T, np.vstack((xerr, yerr)).T, xycov\n",
    "\n",
    "\n",
    "def sqerr(o, l: 'xtrue'):\n",
    "  \"\"\"Squared error loss for estimator output.\"\"\"\n",
    "\n",
    "  return torch.mean((o - l)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import types\n",
    "\n",
    "import numpy as np\n",
    "import scipy.special as scs\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "import torch\n",
    "\n",
    "from truebayes.geometry import xmid, xwid\n",
    "from truebayes.loss import netmeanGn2\n",
    "\n",
    "def makecontour(xytrue, indicator, inputs, net=None, like=None, istart=0, single=True):\n",
    "  pp.figure(figsize=(12,8))\n",
    "\n",
    "  if isinstance(like, types.FunctionType):\n",
    "    like = like(inputs)\n",
    "    \n",
    "  for i in range(6):\n",
    "    netinput = inputs[istart+i:(istart+i+1),:]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      pars = net(netinput).detach().cpu().numpy().flatten()\n",
    "      # xm, xe, xc = netmeanGn2(netinput, net=net)\n",
    "      \n",
    "    xs, ys = np.meshgrid(xmid, xmid, indexing='ij')    \n",
    "    \n",
    "    dx  = pars[0::6] - xs[:,:,np.newaxis]\n",
    "    Fxx = pars[1::6]**2\n",
    "  \n",
    "    dy  = pars[2::6] - ys[:,:,np.newaxis]\n",
    "    Fyy = pars[3::6]**2\n",
    "  \n",
    "    Fxy = np.arctan(pars[4::6]) / (0.5*math.pi) * pars[1::6] * pars[3::6]\n",
    "\n",
    "    \n",
    "    weight = torch.softmax(torch.from_numpy(pars[5::6]),dim=0).numpy()\n",
    "\n",
    "    logmod = scs.logsumexp(np.log(weight) - 0.5*(Fxx*dx*dx + Fyy*dy*dy + 2*Fxy*dx*dy) + 0.5*np.log(Fxx*Fyy - Fxy*Fxy), axis=2)\n",
    "        \n",
    "    q = np.exp(logmod)\n",
    "    q /= np.sum(q)\n",
    "    \n",
    "    pmax = np.max(like[istart+i])\n",
    "    qmax = np.max(q)\n",
    "    vmax = min(pmax, qmax)\n",
    "    \n",
    "    pp.subplot(3,2,i+1)\n",
    "\n",
    "    pp.plot([xytrue[istart+i,0]], [xytrue[istart+i,1]], 'ro')\n",
    "\n",
    "    # note these are set-value posterior levels, not true set-mass-containing contours\n",
    "    pp.contour(xs, ys, like[istart+i], colors='k', alpha=0.3, levels=[0.01*vmax,0.14*vmax,0.61*vmax])\n",
    "    pp.contour(xs, ys, q,              colors='r', alpha=0.3, levels=[0.01*vmax,0.14*vmax,0.61*vmax])\n",
    "\n",
    "\n",
    "def plotgauss(xtrue, indicator, inputs, net=None, like=None, varx=None, twodim=False, istart=0, single=True):  \n",
    "  pp.figure(figsize=(12,8))\n",
    "\n",
    "  if isinstance(like, types.FunctionType):\n",
    "    like = like(inputs)\n",
    "\n",
    "  for i in range(6):\n",
    "    pp.subplot(3,2,i+1)\n",
    "\n",
    "    # make and plot Gaussian mixture\n",
    "    \n",
    "    netinput = inputs[istart+i:(istart+i+1),:]\n",
    "    with torch.no_grad():\n",
    "      pars = net(netinput).detach().cpu().numpy().flatten()\n",
    "    \n",
    "    if twodim:\n",
    "      Fxx, Fyy = pars[1::6]**2, pars[3::6]**2\n",
    "      Fxy = np.arctan(pars[4::6]) / (0.5*math.pi) * pars[1::6] * pars[3::6]\n",
    "      weight = torch.softmax(torch.from_numpy(pars[5::6]),dim=0).numpy()\n",
    "\n",
    "      dx  = (pars[2::6] if varx == 'nu' else pars[0::6]) - xmid[:,np.newaxis]\n",
    "      Cxx = Fxx / (Fxx*Fyy - Fxy*Fxy) if varx == 'nu' else Fyy / (Fxx*Fyy - Fxy*Fxy) \n",
    "\n",
    "      pdf = np.sum(weight * np.exp(-0.5*dx**2/Cxx) / np.sqrt(2*math.pi*Cxx) * xwid, axis=1)\n",
    "\n",
    "      # logmod = scs.logsumexp(np.log(weight) - 0.5*(Fxx*dx*dx + Fyy*dy*dy + 2*Fxy*dx*dy) + 0.5*np.log(Fxx*Fyy - Fxy*Fxy), axis=2)\n",
    "    else:\n",
    "      if len(pars) == 2:\n",
    "        pdf = np.exp(-0.5*(xmid - pars[0])**2/pars[1]**2) / math.sqrt(2*math.pi*pars[1]**2) * xwid\n",
    "      else:\n",
    "        wg = torch.softmax(torch.from_numpy(pars[2::3]), dim=0).numpy()\n",
    "        pdf = np.sum(wg * np.exp(-0.5*(xmid[:,np.newaxis] - pars[0::3])**2/pars[1::3]**2) / np.sqrt(2*math.pi*pars[1::3]**2) * xwid, axis=1)\n",
    "    \n",
    "    pp.plot(xmid, pdf, color='C0')\n",
    "    \n",
    "    # plot likelihood\n",
    "    pp.plot(xmid, like[istart+i], color='C1')\n",
    "\n",
    "    # show true x\n",
    "    if xtrue.ndim == 2:\n",
    "      ix = ['theta_N', 'phi'].index(varx)\n",
    "      pp.axvline(xtrue[istart+i, ix], color='C2', ls=':')\n",
    "    else:\n",
    "      pp.axvline(xtrue[istart+i], color='C2', ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GWFunctions_v3 import h_func_f2\n",
    "#from GWFunctions_v2 import h_func_f2_no_noise\n",
    "#+- 30 degrees from equator\n",
    "cos_theta_min = 0.5\n",
    "cos_theta_max = -0.5\n",
    "phi_min = np.pi\n",
    "phi_max = 3*np.pi/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.36461093e+03+4.31694848e+02j,  1.35865919e+03-4.60337434e+02j,\n",
       "        -1.36205110e+03+4.64607898e+02j,  1.37325783e+03-4.44740087e+02j,\n",
       "        -1.39053682e+03+3.99253105e+02j,  1.41394927e+03-3.26844164e+02j,\n",
       "        -1.43817008e+03+2.28106005e+02j,  1.45645687e+03-9.91727027e+01j,\n",
       "        -1.46406454e+03-5.73731239e+01j,  1.44928121e+03+2.41717476e+02j,\n",
       "        -1.40320595e+03-4.50350348e+02j,  1.31478626e+03+6.76436375e+02j,\n",
       "        -1.17411256e+03-9.07385395e+02j,  9.69899632e+02+1.12947439e+03j,\n",
       "        -6.99878440e+02-1.31934165e+03j,  3.64977471e+02+1.45357761e+03j,\n",
       "         2.28018817e+01-1.50405363e+03j, -4.41218849e+02+1.44356096e+03j,\n",
       "         8.53133749e+02-1.25189046e+03j, -1.20946232e+03+9.21863741e+02j,\n",
       "         1.45398562e+03-4.64240122e+02j, -1.53027405e+03-8.22117427e+01j,\n",
       "         1.39460699e+03+6.50049590e+02j, -1.03060739e+03-1.15109733e+03j,\n",
       "         4.66379768e+02+1.47947780e+03j,  2.17952826e+02-1.54131128e+03j,\n",
       "        -8.92788200e+02+1.28345393e+03j,  1.39647166e+03-7.16245183e+02j,\n",
       "        -1.57534196e+03-5.84542390e+01j,  1.33355658e+03+8.52794589e+02j,\n",
       "        -6.88024855e+02-1.43360777e+03j, -2.06210567e+02+1.58410335e+03j,\n",
       "         1.06781769e+03-1.19740351e+03j, -1.57204864e+03+3.53270588e+02j,\n",
       "         1.47595155e+03+6.65392728e+02j, -7.50279198e+02-1.44216955e+03j,\n",
       "        -3.41636967e+02+1.59769037e+03j,  1.30934723e+03-9.88680637e+02j,\n",
       "        -1.64225724e+03-1.49684830e+02j,  1.09200425e+03+1.24642631e+03j,\n",
       "         1.09426479e+02-1.66176457e+03j, -1.28413057e+03+1.07236066e+03j,\n",
       "         1.66505071e+03+2.30299880e+02j, -9.19939447e+02-1.41715028e+03j,\n",
       "        -5.13827699e+02+1.61840154e+03j,  1.60051378e+03-5.94490174e+02j,\n",
       "        -1.43750438e+03-9.36053778e+02j,  6.11872336e+01+1.72335974e+03j,\n",
       "         1.40917680e+03-1.01082910e+03j, -1.61394817e+03-6.59059485e+02j,\n",
       "         2.55842249e+02+1.73338913e+03j,  1.39750586e+03-1.07384473e+03j,\n",
       "        -1.60741238e+03-7.45800146e+02j,  3.61756561e+01+1.78131753e+03j,\n",
       "         1.61417336e+03-7.76577804e+02j, -1.35125856e+03-1.19152456e+03j,\n",
       "        -6.21318645e+02+1.70177786e+03j,  1.82191901e+03+9.76723055e+00j,\n",
       "        -5.61312137e+02-1.74435051e+03j, -1.52290826e+03+1.03972823e+03j,\n",
       "         1.40313022e+03+1.21234969e+03j,  8.65508347e+02-1.65278933e+03j,\n",
       "        -1.80322104e+03-5.21410401e+02j, -2.06966821e+02+1.87713545e+03j,\n",
       "         1.89860058e+03-5.99737973e+01j, -2.70918807e+02-1.89203282e+03j,\n",
       "        -1.87607733e+03+4.25802403e+02j,  5.21137720e+02+1.86351886e+03j,\n",
       "         1.86544396e+03-5.59104830e+02j, -5.38586384e+02-1.88418327e+03j,\n",
       "        -1.91939044e+03+4.57352798e+02j,  3.09975802e+02+1.96154609e+03j,\n",
       "         1.99663668e+03-9.45691430e+01j,  1.90855964e+02-2.00273025e+03j,\n",
       "        -1.95183615e+03-5.40253900e+02j, -9.39818920e+02+1.80856286e+03j,\n",
       "         1.53945417e+03+1.35727916e+03j,  1.73844796e+03-1.11745004e+03j,\n",
       "        -5.33041876e+02-2.01073549e+03j, -2.08723796e+03-1.84828082e+02j,\n",
       "        -9.56920232e+02+1.88035996e+03j,  1.33772865e+03+1.64980000e+03j,\n",
       "         2.08515457e+03-4.79367954e+02j,  5.65582818e+02-2.07871515e+03j,\n",
       "        -1.52005419e+03-1.54835224e+03j, -2.13831722e+03+4.55240675e+02j,\n",
       "        -8.47573748e+02+2.03181171e+03j,  1.12621709e+03+1.91134949e+03j,\n",
       "         2.21004977e+03+3.34308576e+02j,  1.72350797e+03-1.44788799e+03j,\n",
       "         1.42702470e+02-2.26388873e+03j, -1.48191516e+03-1.74033111e+03j,\n",
       "        -2.28164941e+03-3.17459305e+02j, -1.98180981e+03+1.20841024e+03j,\n",
       "        -8.67360347e+02+2.17282812e+03j,  5.17135374e+02+2.30050666e+03j,\n",
       "         1.66942651e+03+1.69088439e+03j,  2.30348144e+03+6.57621420e+02j,\n",
       "         2.36980035e+03-4.59648803e+02j,  1.98649999e+03-1.40657297e+03j,\n",
       "         1.33600632e+03-2.05757822e+03j,  5.96443628e+02-2.40078209e+03j,\n",
       "        -1.06256817e+02-2.49235828e+03j, -6.96128295e+02-2.41678456e+03j,\n",
       "        -1.14964100e+03-2.26126825e+03j, -1.46870369e+03-2.09504701e+03j,\n",
       "        -1.66823304e+03-1.96849195e+03j, -1.76174862e+03-1.91476988e+03j,\n",
       "        -1.75747793e+03-1.94944674e+03j, -1.64770939e+03-2.07381654e+03j,\n",
       "        -1.41161606e+03-2.26892951e+03j, -1.02049768e+03-2.49553314e+03j,\n",
       "        -4.47540521e+02-2.68291094e+03j,  3.08479639e+02-2.72773977e+03j,\n",
       "         1.19640633e+03-2.49786229e+03j,  2.07719497e+03-1.87041566e+03j,\n",
       "         2.70871576e+03-7.91425952e+02j,  2.77706570e+03+6.31914093e+02j,\n",
       "         2.02002804e+03+2.04619706e+03j,  4.35342263e+02+2.87046555e+03j,\n",
       "        -1.50855031e+03+2.51377935e+03j, -2.84718386e+03+8.08207375e+02j,\n",
       "        -2.56206595e+03-1.54064310e+03j, -4.40697109e+02-2.98711807e+03j,\n",
       "         2.19531956e+03-2.11726645e+03j,  2.98546177e+03+7.62214573e+02j,\n",
       "         7.22845867e+02+3.02765928e+03j, -2.50569986e+03+1.90015601e+03j,\n",
       "        -2.65856322e+03-1.73994809e+03j,  9.80077575e+02-3.05836530e+03j,\n",
       "         3.22431950e+03+3.72245037e+02j,  1.41864031e+01+3.28131296e+03j,\n",
       "        -3.31396818e+03+1.53261816e+02j, -3.02596831e+01-3.35413903e+03j,\n",
       "         3.37138743e+03+3.68013102e+02j, -1.04388141e+03+3.26753541e+03j,\n",
       "        -2.87507907e+03-1.94041263e+03j,  2.88315920e+03-2.00034645e+03j,\n",
       "         5.25026061e+02+3.51176338e+03j, -3.30882795e+03-1.39853599e+03j,\n",
       "         3.13607002e+03-1.83936958e+03j, -7.44221240e+02+3.60403554e+03j,\n",
       "        -1.90337156e+03-3.20269993e+03j,  3.48419354e+03+1.44410835e+03j,\n",
       "        -3.77783987e+03+5.60709570e+02j,  3.22721156e+03-2.13378161e+03j,\n",
       "        -2.39138997e+03+3.10450597e+03j,  1.67302813e+03-3.60090684e+03j,\n",
       "        -1.28548751e+03+3.81256596e+03j,  1.32385593e+03-3.85712464e+03j,\n",
       "        -1.81396105e+03+3.71574497e+03j,  2.69794032e+03-3.20917695e+03j,\n",
       "        -3.72735131e+03+2.04469111e+03j,  4.31302999e+03-1.40880812e+01j,\n",
       "        -3.54317872e+03-2.56931226e+03j,  7.78071647e+02+4.37321325e+03j,\n",
       "         3.01325048e+03-3.35416508e+03j, -4.47347379e+03-9.74159065e+02j,\n",
       "         7.08689859e+02+4.59602335e+03j,  4.41226650e+03-1.68834148e+03j,\n",
       "        -1.94648754e+03-4.38862084e+03j, -4.65789321e+03+1.45712489e+03j,\n",
       "         8.44639329e+01+4.96177575e+03j,  4.55099543e+03+2.18531753e+03j,\n",
       "         4.57220596e+03-2.34057025e+03j,  1.88894306e+03-4.87646469e+03j,\n",
       "        -8.38879572e+02-5.25872028e+03j, -2.49034696e+03-4.81893479e+03j,\n",
       "        -3.02039591e+03-4.63110027e+03j, -2.45860924e+03-5.07226867e+03j,\n",
       "        -4.97443537e+02-5.72888605e+03j,  2.95317115e+03-5.07186442e+03j,\n",
       "         5.90822093e+03-1.00182068e+03j,  3.39731586e+03+5.09286885e+03j,\n",
       "        -4.70972481e+03+4.12268835e+03j, -3.31386396e+03-5.47787746e+03j,\n",
       "         6.54628179e+03-3.01338391e+02j, -4.79001570e+03+4.70236821e+03j,\n",
       "         2.85865952e+03-6.25863206e+03j, -3.07352677e+03+6.35362397e+03j,\n",
       "         5.61933779e+03-4.57664703e+03j, -7.30191264e+03-1.46870564e+03j,\n",
       "         8.41798554e+01+7.66085466e+03j,  7.54247259e+03+2.31415900e+03j,\n",
       "         7.48858662e+03-3.17618638e+03j,  7.42912225e+03-3.91409007e+03j,\n",
       "         8.63110936e+03+9.32123509e+02j,  1.09834212e+03+8.92029049e+03j,\n",
       "        -8.25750917e+03-4.32265316e+03j,  8.69087462e+03+4.26883869e+03j,\n",
       "        -6.89756841e+02-1.00564562e+04j, -8.41226995e+03-6.31357568e+03j,\n",
       "        -3.58362430e+03-1.04031238e+04j,  1.04560180e+04+4.89010552e+03j,\n",
       "         2.64602167e+03-1.18561177e+04j,  1.19451010e+04-4.69006116e+03j,\n",
       "        -4.68921465e+03-1.27758283e+04j, -7.61487822e+03+1.23262285e+04j,\n",
       "        -1.41557904e+04-6.13038256e+03j,  1.71583141e+04+2.22410084e+03j]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_func_f2((0.5, np.pi/2), noise_ind=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntrain(size,  region=[[cos_theta_min, cos_theta_max], [phi_min, phi_max]], varx='theta_N', \n",
    "             varall=True, seed=None, single=True, noise=1):\n",
    "    \"\"\"Makes a training set using the ROMAN NN. It returns labels (for `varx`,\n",
    "        or for all if `varall=True`), indicator vectors, and ROM coefficients\n",
    "        (with `snr` and `noise`). Note that the coefficients are kept on the GPU.\n",
    "        Parameters are sampled randomly within `region`.\"\"\"\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu:0'\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        xs = torch.zeros((size,2), dtype=torch.float, device=device)\n",
    "\n",
    "        for i, r in enumerate(region):\n",
    "            xs[:,i] = r[0] + (r[1] - r[0]) * torch.rand((size,), dtype=torch.float, device=device)\n",
    "        \n",
    "        xs_1 = xs.detach().cpu().double().numpy()\n",
    "        \n",
    "        #generating signals\n",
    "        signal = np.apply_along_axis(h_func_f2, 1, xs_1, noise)[:,:,0]\n",
    "            \n",
    "        signal_r, signal_i = numpy2cuda(signal.real), numpy2cuda(signal.imag)\n",
    "        \n",
    "        #setting up real and imag alphas\n",
    "        alphas = torch.zeros((size, 200*2), dtype=torch.float if single else torch.double, device=device)\n",
    "        \n",
    "        alphas[:,0::2] = signal_r \n",
    "        alphas[:,1::2] = signal_i \n",
    "\n",
    "    xr = xs.detach().cpu().double().numpy()\n",
    "\n",
    "    del xs, signal_r, signal_i\n",
    "\n",
    "      # normalize (for provided regions)\n",
    "    for i, r in enumerate(region):\n",
    "        xr[:,i] = (xr[:,i] - r[0]) / (r[1] - r[0])\n",
    "\n",
    "    if isinstance(varx, list):\n",
    "        ix = ['theta_N','phi'].index(varx[0])\n",
    "        jx = ['theta_N','phi'].index(varx[1])    \n",
    "\n",
    "        i = np.digitize(xr[:,ix], xstops, False) - 1\n",
    "        i[i == -1] = 0; i[i == qdim] = qdim - 1\n",
    "        px = np.zeros((size, qdim), 'd'); px[range(size), i] = 1\n",
    "\n",
    "        j = np.digitize(xr[:,jx], xstops, False) - 1\n",
    "        j[j == -1] = 0; j[j == qdim] = qdim - 1\n",
    "        py = np.zeros((size, qdim), 'd'); py[range(size), j] = 1\n",
    "\n",
    "        if varall:\n",
    "            return xr, np.einsum('ij,ik->ijk', px, py), alphas\n",
    "        else:\n",
    "            return xr[:,[ix,jx]], np.einsum('ij,ik->ijk', px, py), alphas    \n",
    "    else:\n",
    "        ix = ['theta_N','phi'].index(varx)\n",
    "\n",
    "        i = np.digitize(xr[:,ix], xstops, False) - 1\n",
    "        i[i == -1] = 0; i[i == qdim] = qdim - 1\n",
    "        px = np.zeros((size, qdim), 'd'); px[range(size), i] = 1\n",
    "\n",
    "        if varall:\n",
    "            return xr, px, alphas\n",
    "        else:\n",
    "            return xr[:,ix], px, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "syntrain(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntrainer(net, syntrain, lossfunction=None, iterations=300, \n",
    "               batchsize=None, initstep=1e-3, finalv=1e-5, clipgradient=None, validation=None,\n",
    "               seed=None, single=True):\n",
    "  \"\"\"Trains network NN against training sets obtained from `syntrain`,\n",
    "  iterating at most `iterations`; stops if the derivative of loss\n",
    "  (averaged over 20 epochs) becomes less than `finalv`.\"\"\"\n",
    "\n",
    "  if seed is not None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "  indicatorloss = 'l' in lossfunction.__annotations__ and lossfunction.__annotations__['l'] == 'indicator'  \n",
    "  \n",
    "  if validation is not None:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    vlabels = numpy2cuda(validation[1] if indicatorloss else validation[0], single)\n",
    "    vinputs = numpy2cuda(validation[2], single)\n",
    "  \n",
    "  optimizer = optim.Adam(net.parameters(), lr=initstep)\n",
    "\n",
    "  training_loss, validation_loss = [], []\n",
    "  \n",
    "  for epoch in range(iterations):\n",
    "    t0 = time.time()\n",
    "\n",
    "    xtrue, indicator, inputs = syntrain()\n",
    "    labels = numpy2cuda(indicator if indicatorloss else xtrue, single)\n",
    "\n",
    "    if batchsize is None:\n",
    "      batchsize = inputs.shape[0]\n",
    "    batches = inputs.shape[0] // batchsize\n",
    "\n",
    "    averaged_loss = 0.0    \n",
    "    \n",
    "    for i in range(batches):\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # forward + backward + optimize\n",
    "      outputs = net(inputs[i*batchsize:(i+1)*batchsize])\n",
    "      loss = lossfunction(outputs, labels[i*batchsize:(i+1)*batchsize])\n",
    "      loss.backward()\n",
    "      \n",
    "      if clipgradient is not None:\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), clipgradient)\n",
    "      \n",
    "      optimizer.step()\n",
    "\n",
    "      # print statistics\n",
    "      averaged_loss += loss.item()\n",
    "\n",
    "    training_loss.append(averaged_loss/batches)\n",
    "\n",
    "    if validation is not None:\n",
    "      loss = lossfunction(net(vinputs), vlabels)\n",
    "      validation_loss.append(loss.detach().cpu().item())\n",
    "\n",
    "    if epoch == 1:\n",
    "      print(\"One epoch = {:.1f} seconds.\".format(time.time() - t0))\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "      print(epoch,training_loss[-1],validation_loss[-1] if validation is not None else '')\n",
    "\n",
    "    try:\n",
    "      if len(training_loss) > iterations/10:\n",
    "        training_rate = np.polyfit(range(20), training_loss[-20:], deg=1)[0]\n",
    "        if training_rate < 0 and training_rate > -finalv:\n",
    "          print(f\"Terminating at epoch {epoch} because training loss stopped improving sufficiently: rate = {training_rate}\")\n",
    "          break\n",
    "\n",
    "      if len(validation_loss) > iterations/10:\n",
    "        validation_rate = np.polyfit(range(20), validation_loss[-20:], deg=1)[0]        \n",
    "        if validation_rate > 0:\n",
    "          print(f\"Terminating at epoch {epoch} because validation loss started worsening: rate = {validation_rate}\")\n",
    "          break\n",
    "    except:\n",
    "      pass\n",
    "          \n",
    "  print(\"Final\",training_loss[-1],validation_loss[-1] if validation is not None else '')\n",
    "      \n",
    "  if hasattr(net,'steps'):\n",
    "    net.steps += iterations\n",
    "  else:\n",
    "    net.steps = iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [200*2] + [1024]*8 + [1*6]\n",
    "percival_network = makenet(dimensions, softmax=False)\n",
    "\n",
    "network_to_use = percival_network()\n",
    "\n",
    "##Training data to pass through Percival network\n",
    "training_data = lambda: syntrain(size=100000, varx='theta_N')\n",
    "\n",
    "##Train Percival network on above data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 2.87 GiB already allocated; 0 bytes free; 2.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-dcb50b795d89>\u001b[0m in \u001b[0;36msyntrainer\u001b[1;34m(net, syntrain, lossfunction, iterations, batchsize, initstep, finalv, clipgradient, validation, seed, single)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m       \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m       \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programming\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b84c1b70aa60>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m       \u001b[1;31m# per Alvin's recipe, apply relu everywhere but last layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'fc{l}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'fc{ndims - 2}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programming\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1473\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1475\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1476\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 2.87 GiB already allocated; 0 bytes free; 2.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##training the network\n",
    "syntrainer(network_to_use, training_data, lossfunction=kllossGn2, iterations=100,\n",
    "           initstep=1e-4, finalv=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\\\Users\\\\Luke\\\\year-4-project-lisa\\\\Luke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network_to_use.state_dict(), PATH + '\\\\Trained-Networks\\\\theta-phi_l200-1024x8_2d.pt') \n",
    "#insert name for net e.g #percival/Mc-nu_l1024x8_g1_SNR8-16_2d.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_to_use.load_state_dict(torch.load(PATH + '\\\\Trained-Networks\\\\theta-phi_l200-1024x8_2d.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutest = syntrain(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_N = mutest[0][:,0]\n",
    "phi = mutest[0][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(theta_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from truebayes.utils import numpy2cuda, cuda2numpy\n",
    "\n",
    "\n",
    "def synlike(a, syntrain, iterations=1000000):\n",
    "  with torch.no_grad():\n",
    "    # note aimag defined with plus here, exp below modified consistently\n",
    "    # [areal] = [aimag] = nbasis x nsignals \n",
    "    areal, aimag = torch.t(a[:,0::2]), torch.t(a[:,1::2])\n",
    "\n",
    "    # [anorm] = nsignals\n",
    "    anorm = torch.sum(areal*areal + aimag*aimag, dim=0)\n",
    "    \n",
    "    cnt, norm, like = 0, 0, 0\n",
    "    adapt = None\n",
    "    while cnt < iterations:\n",
    "      # [pxt] = nbatch x qdim\n",
    "      _, pxt, alpha = syntrain()\n",
    "      cnt = cnt + alpha.shape[0]\n",
    "\n",
    "      # cpxt = torch.from_numpy(pxt).cuda()\n",
    "      # handle 2D indicator array (assume square qdim)\n",
    "      cpxt = numpy2cuda(pxt if pxt.ndim == 2 else pxt.reshape((pxt.shape[0], pxt.shape[1]*pxt.shape[1])),\n",
    "                        alpha.dtype == torch.float32)\n",
    "      \n",
    "      # [alphareal] = [alphaimag] = nbatch x nbasis\n",
    "      alphareal, alphaimag = alpha[:,0::2], alpha[:,1::2]\n",
    "\n",
    "      # [norm] = qdim\n",
    "      norm += torch.sum(cpxt, dim=0)\n",
    "      \n",
    "      # [alphanorm] = nbatch\n",
    "      alphanorm = torch.sum(alphareal*alphareal + alphaimag*alphaimag, dim=1)\n",
    "\n",
    "      # automatic normalization of exponentials based on the first batch\n",
    "      loglike = (alphareal @ areal + alphaimag @ aimag - 0.5*alphanorm.unsqueeze(1) - 0.5*anorm)*1/100000\n",
    "      if adapt is None:\n",
    "        adapt = torch.max(loglike, dim=0)[0]\n",
    "      loglike -= adapt\n",
    "\n",
    "      # [like] = qdim x nsignals = (qdim x nbatch) @ [(nbatch x nbasis) @ (nbasis x nsignals) + (nbatch x 1) + nsignals]\n",
    "      # remember broadcasting tries to match the last dimension [so A @ b = sum(A * b,axis=1)]\n",
    "      like += torch.t(cpxt) @ torch.exp(loglike)\n",
    "\n",
    "    # (qdim x nsignals) * (qdim x 1)\n",
    "    like = like / norm.unsqueeze(1)  \n",
    "    \n",
    "    # [ret] = nsignals x qdim = (nsignals x qdim) * qdim\n",
    "    ret = torch.t(like / torch.sum(like, dim=0))\n",
    "    \n",
    "    nret = ret.detach().cpu().numpy()\n",
    "    \n",
    "  return nret if pxt.ndim == 2 else nret.reshape((nret.shape[0], pxt.shape[1], pxt.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeset_theta_N = lambda: syntrain(size=10000, varx='theta_N', region=[[cos_theta_min, cos_theta_max], [phi_min, phi_max]], noise=0)\n",
    "likeset_phi = lambda: syntrain(size=10000, varx='phi', region=[[cos_theta_min, cos_theta_max], [phi_min, phi_max]], noise=0)\n",
    "likeset_2 = lambda: syntrain(size=10000, varx=['theta_N','phi'], region=[[cos_theta_min, cos_theta_max], [phi_min, phi_max]], noise=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sl_theta_N = synlike(mutest[2][:24,:], likeset_theta_N, iterations=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sl_phi = synlike(mutest[2][:24,:], likeset_phi, iterations=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotgauss(*mutest, net=network_to_use, varx='theta_N', like=sl_theta_N, twodim=True, istart=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
